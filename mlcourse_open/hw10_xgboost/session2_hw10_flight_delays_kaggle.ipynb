{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 2\n",
    "Автор материала: программист-исследователь Mail.ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ Юрий Кашницкий. Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Домашнее задание № 10\n",
    "## <center> Прогнозирование задержек вылетов\n",
    "\n",
    "Ваша задача – побить как минимум 2 бенчмарка в [соревновании](https://www.kaggle.com/c/flight-delays-2017) на Kaggle Inclass. Подробных инструкций не будет, будет только тезисно описано, как получен второй – с помощью Xgboost. Надеюсь, на данном этапе курса вам достаточно бросить полтора взгляда на данные, чтоб понять, что это тот тип задачи, в которой затащит градиентный бустинг. Скорее всего Xgboost, но тут у нас еще немало категориальных признаков...\n",
    "\n",
    "<img src='../../img/xgboost_meme.jpg' width=40% />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../data/hw10_xgboost/flight_delays_train.csv')\n",
    "test = pd.read_csv('../../data/hw10_xgboost/flight_delays_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, надо по времени вылета самолета, коду авиакомпании-перевозчика, месту вылета и прилета и расстоянию между аэропортами вылета и прилета предсказать задержку вылета более 15 минут. В качестве простейшего бенчмарка возьмем логистическую регрессию и два признака, которые проще всего взять: `DepTime` и `Distance`. У такой модели результат – 0.68202 на LB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = train[['Distance', 'DepTime']].values, train['dep_delayed_15min'].map({'Y': 1, 'N': 0}).values\n",
    "X_test = test[['Distance', 'DepTime']].values\n",
    "\n",
    "X_train_part, X_valid, y_train_part, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=17)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_part = scaler.fit_transform(X_train_part)\n",
    "X_valid = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67956914653526068"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "\n",
    "logit.fit(X_train_part, y_train_part)\n",
    "logit_valid_pred = logit.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "roc_auc_score(y_valid, logit_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "logit.fit(X_train_scaled, y_train)\n",
    "logit_test_pred = logit.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "pd.Series(logit_test_pred, name='dep_delayed_15min').to_csv('logit_2feat.csv', index_label='id', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй бенчмарк, представленный в рейтинге соревнования, был получен так:\n",
    "- Признаки `Distance` и  `DepTime` брались без изменений\n",
    "- Создан признак \"маршрут\" из исходных `Origin` и `Dest`\n",
    "- К признакам `Month`, `DayofMonth`, `DayOfWeek`, `UniqueCarrier` и \"маршрут\" применено OHE-преобразование (`LabelBinarizer`)\n",
    "- Выделена отложенная выборка\n",
    "- Обучалась логистическая регрессия и градиентный бустинг (xgboost), гиперпараметры бустинга настраивались на кросс-валидации, сначала те, что отвечают за сложность модели, затем число деревьев фиксировалось равным 500 и настраивался шаг градиентного спуска\n",
    "- С помощью `cross_val_predict` делались прогнозы обеих моделей на кросс-валидации (именно предсказанные вероятности), настраивалась линейная смесь ответов логистической регрессии и градиентного бустинга вида $w_1 * p_{logit} + (1 - w_1) * p_{xgb}$, где $p_{logit}$ – предсказанные логистической регрессией вероятности класса 1, $p_{xgb}$ – аналогично. Вес $w_1$ подбирался вручную. \n",
    "- В качестве ответа для тестовой выборки бралась аналогичная комбинация ответов двух моделей, но уже обученных на всей обучающей выборке.\n",
    "\n",
    "Описанный план ни к чему не обязывает – это просто то, как решение получил автор задания. Возможно, вы не захотите следовать намеченному плану, а добавите, скажем, пару хороших признаков и обучите лес из тысячи деревьев.\n",
    "\n",
    "Удачи!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.86 s, sys: 72 ms, total: 3.93 s\n",
      "Wall time: 3.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_new = train.copy()\n",
    "test_new = test.copy()\n",
    "\n",
    "train_new[\"Route\"] = train_new[\"Origin\"] + \"_\" + train_new[\"Dest\"]\n",
    "test_new[\"Route\"] = test_new[\"Origin\"] + \"_\" + test_new[\"Dest\"]\n",
    "\n",
    "lb = LabelBinarizer(sparse_output=True)\n",
    "\n",
    "route_train = lb.fit_transform(train_new[\"Route\"])\n",
    "route_test = lb.transform(test_new[\"Route\"])\n",
    "\n",
    "month_train = lb.fit_transform(train_new[\"Month\"])\n",
    "month_test = lb.transform(test_new[\"Month\"])\n",
    "\n",
    "day_of_month_train = lb.fit_transform(train_new[\"DayofMonth\"])\n",
    "day_of_month_test = lb.transform(test_new[\"DayofMonth\"])\n",
    "\n",
    "day_of_week_train = lb.fit_transform(train_new[\"DayOfWeek\"])\n",
    "day_of_week_test = lb.transform(test_new[\"DayOfWeek\"])\n",
    "\n",
    "uniq_carrier_train = lb.fit_transform(train_new[\"UniqueCarrier\"])\n",
    "uniq_carrier_test = lb.transform(test_new[\"UniqueCarrier\"])\n",
    "\n",
    "# train_new[[\"bin_\" + cls for cls in lb.classes_]] = pd.DataFrame(lb.transform(train_new[\"Route\"]))\n",
    "# test_new[[\"bin_\" + cls for cls in lb.classes_]] = pd.DataFrame(lb.transform(test_new[\"Route\"]))\n",
    "\n",
    "# lb.fit(train_new[\"Month\"])\n",
    "# train_new[[\"bin_\" + cls for cls in lb.classes_]] = pd.DataFrame(lb.transform(train_new[\"Month\"]))\n",
    "# test_new[[\"bin_\" + cls for cls in lb.classes_]] = pd.DataFrame(lb.transform(test_new[\"Month\"]))\n",
    "\n",
    "# lb.fit(train_new[\"DayofMonth\"])\n",
    "# train_new[[\"bin_\" + cls for cls in lb.classes_]] = pd.DataFrame(lb.transform(train_new[\"DayofMonth\"]))\n",
    "# test_new[[\"bin_\" + cls for cls in lb.classes_]] = pd.DataFrame(lb.transform(test_new[\"DayofMonth\"]))\n",
    "\n",
    "# lb.fit(train_new[\"DayOfWeek\"])\n",
    "# train_new[[\"bin_\" + cls for cls in lb.classes_]] = pd.DataFrame(lb.transform(train_new[\"DayOfWeek\"]))\n",
    "# test_new[[\"bin_\" + cls for cls in lb.classes_]] = pd.DataFrame(lb.transform(test_new[\"DayOfWeek\"]))\n",
    "\n",
    "# lb.fit(train_new[\"UniqueCarrier\"])\n",
    "# train_new[[\"bin_\" + cls for cls in lb.classes_]] = pd.DataFrame(lb.transform(train_new[\"UniqueCarrier\"]))\n",
    "# test_new[[\"bin_\" + cls for cls in lb.classes_]] = pd.DataFrame(lb.transform(test_new[\"UniqueCarrier\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 4503), (100000, 4503))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new = hstack([X_train_scaled, route_train, month_train, day_of_month_train, day_of_week_train, uniq_carrier_train])\n",
    "X_test_new = hstack([X_test_scaled, route_test, month_test, day_of_month_test, day_of_week_test, uniq_carrier_test])\n",
    "\n",
    "X_train_new.shape, X_test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_part, X_valid, y_train_part, y_valid = train_test_split(X_train_new, y_train, test_size=0.3, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    from sklearn.metrics import log_loss\n",
    "    print(\"Training with params:\")\n",
    "    print(params)\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    dtrain = xgb.DMatrix(X_train_part, label=y_train_part)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "    model = xgb.train(params, dtrain, params['num_round'])\n",
    "    predictions = model.predict(dvalid)\n",
    "    score = log_loss(y_valid, predictions)\n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    return {'loss': score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(trials):\n",
    "    space = {\n",
    "             'num_round': 100,\n",
    "             'learning_rate': hp.quniform('eta', 0.005, 0.05, 0.005),\n",
    "             'max_depth': hp.quniform('max_depth', 3, 18, 1),\n",
    "             'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1),\n",
    "             'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "             'gamma': hp.quniform('gamma', 0.5, 1, 0.01),\n",
    "             'objective': 'binary:logistic',\n",
    "             'nthread' : 4,\n",
    "             'silent' : 1\n",
    "             }\n",
    "    \n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=10)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:\n",
      "{'min_child_weight': 6.0, 'silent': 1, 'learning_rate': 0.005, 'nthread': 4, 'objective': 'binary:logistic', 'gamma': 0.68, 'num_round': 100, 'max_depth': 3.0, 'subsample': 0.8}\n",
      "\tScore 0.5534719979981582\n",
      "\n",
      "\n",
      "Training with params:\n",
      "{'min_child_weight': 2.0, 'silent': 1, 'learning_rate': 0.03, 'nthread': 4, 'objective': 'binary:logistic', 'gamma': 0.5700000000000001, 'num_round': 100, 'max_depth': 7.0, 'subsample': 0.65}\n",
      "\tScore 0.4368425001559779\n",
      "\n",
      "\n",
      "Training with params:\n",
      "{'min_child_weight': 6.0, 'silent': 1, 'learning_rate': 0.035, 'nthread': 4, 'objective': 'binary:logistic', 'gamma': 0.89, 'num_round': 100, 'max_depth': 11.0, 'subsample': 0.9}\n",
      "\tScore 0.43229486943936596\n",
      "\n",
      "\n",
      "Training with params:\n",
      "{'min_child_weight': 7.0, 'silent': 1, 'learning_rate': 0.015, 'nthread': 4, 'objective': 'binary:logistic', 'gamma': 0.89, 'num_round': 100, 'max_depth': 8.0, 'subsample': 0.8500000000000001}\n",
      "\tScore 0.4598031818434596\n",
      "\n",
      "\n",
      "Training with params:\n",
      "{'min_child_weight': 4.0, 'silent': 1, 'learning_rate': 0.01, 'nthread': 4, 'objective': 'binary:logistic', 'gamma': 0.6, 'num_round': 100, 'max_depth': 13.0, 'subsample': 0.75}\n",
      "\tScore 0.48537994950513047\n",
      "\n",
      "\n",
      "Training with params:\n",
      "{'min_child_weight': 5.0, 'silent': 1, 'learning_rate': 0.025, 'nthread': 4, 'objective': 'binary:logistic', 'gamma': 0.67, 'num_round': 100, 'max_depth': 16.0, 'subsample': 0.6000000000000001}\n",
      "\tScore 0.4358780160808315\n",
      "\n",
      "\n",
      "Training with params:\n",
      "{'min_child_weight': 5.0, 'silent': 1, 'learning_rate': 0.005, 'nthread': 4, 'objective': 'binary:logistic', 'gamma': 0.84, 'num_round': 100, 'max_depth': 13.0, 'subsample': 0.75}\n",
      "\tScore 0.5483879711498817\n",
      "\n",
      "\n",
      "Training with params:\n",
      "{'min_child_weight': 1.0, 'silent': 1, 'learning_rate': 0.05, 'nthread': 4, 'objective': 'binary:logistic', 'gamma': 0.56, 'num_round': 100, 'max_depth': 14.0, 'subsample': 0.55}\n",
      "\tScore 0.42849507812540977\n",
      "\n",
      "\n",
      "Training with params:\n",
      "{'min_child_weight': 2.0, 'silent': 1, 'learning_rate': 0.015, 'nthread': 4, 'objective': 'binary:logistic', 'gamma': 0.89, 'num_round': 100, 'max_depth': 7.0, 'subsample': 0.5}\n",
      "\tScore 0.45992581055015325\n",
      "\n",
      "\n",
      "Training with params:\n",
      "{'min_child_weight': 7.0, 'silent': 1, 'learning_rate': 0.015, 'nthread': 4, 'objective': 'binary:logistic', 'gamma': 0.91, 'num_round': 100, 'max_depth': 17.0, 'subsample': 0.6000000000000001}\n",
      "\tScore 0.45676974268903336\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eta': 0.05,\n",
       " 'gamma': 0.56,\n",
       " 'max_depth': 14.0,\n",
       " 'min_child_weight': 1.0,\n",
       " 'subsample': 0.55}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_params = optimize(trials)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params['max_depth'] = int(best_params['max_depth'])\n",
    "best_params['objective'] = 'binary:logistic'\n",
    "best_params['nthread'] = 4\n",
    "best_params['silent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 13s, sys: 6.07 s, total: 5min 19s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgbCvResult = xgb.cv(best_params, dtrain, \n",
    "                      num_boost_round=500,  \n",
    "                      nfold=3, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_num_round = np.argmin(xgbCvResult['test-error-mean'])\n",
    "best_num_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestXgb = xgb.train(best_params, dtrain, num_boost_round=best_num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgboost_predict_proba = bestXgb.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Series(xgboost_predict_proba, name='dep_delayed_15min').to_csv('xgboost3.csv', index_label='id', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
