{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"../../data/kaggle_alice/\"\n",
    "!PATH_TO_DATA=../../data/kaggle_alice/\n",
    "\n",
    "INP_TRAIN = \"train_sessions.csv\"\n",
    "INP_TEST  = \"test_sessions.csv\"\n",
    "SITE_DIC = \"site_dic.pkl\"\n",
    "SAMPLE_SUBMIT = \"sample_submission.csv\"\n",
    "\n",
    "!INP_TRAIN=train_sessions.csv\n",
    "!INP_TEST=test_sessions.csv\n",
    "!SITE_DIC=site_dic.pkl\n",
    "!SAMPLE_SUBMIT=sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times = [\"time%s\" % i for i in range(1, 11)]\n",
    "sites = [\"site%s\" % i for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_TO_DATA + SITE_DIC, \"rb\") as inp_file:\n",
    "    site_dic = pickle.load(inp_file)\n",
    "\n",
    "inv_site_dic = {v: k for k, v in site_dic.items()}\n",
    "inv_site_dic[0] = \"none_none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(PATH_TO_DATA + INP_TRAIN, \n",
    "                       index_col=\"session_id\", \n",
    "                       parse_dates=times).sort_values(by=\"time1\")\n",
    "train_df[sites] = train_df[sites].fillna(0).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(PATH_TO_DATA + INP_TEST, \n",
    "                       index_col=\"session_id\", \n",
    "                       parse_dates=times)\n",
    "test_df[sites] = test_df[sites].fillna(0).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41602, 41600, 9088)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_uniq_sites = set(train_df[sites].values.flatten())\n",
    "\n",
    "train_sites = pd.DataFrame(index=train_df.index)\n",
    "test_sites = pd.DataFrame(index=test_df.index)\n",
    "\n",
    "for site in sites:\n",
    "    # transform train sites\n",
    "#     train_sites[site] = train_df[site].map(lambda x: inv_site_dic[x])\n",
    "    train_sites[site] = train_df[site].map(lambda x: inv_site_dic[x].replace(\".\", \"_\").replace(\"-\", \"_\"))\n",
    "    # transform test sites\n",
    "    test_sites[site] = test_df[site].map(lambda x: inv_site_dic[x].replace(\".\", \"_\").replace(\"-\", \"_\") \n",
    "                                         if x in train_uniq_sites else \"unknown_unknown\")\n",
    "    \n",
    "len(train_uniq_sites), len(set(train_sites[sites].values.flatten())), len(set(test_sites[sites].values.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>safebrowsing_clients_google_com</td>\n",
       "      <td>safebrowsing_cache_google_com</td>\n",
       "      <td>none_none</td>\n",
       "      <td>none_none</td>\n",
       "      <td>none_none</td>\n",
       "      <td>none_none</td>\n",
       "      <td>none_none</td>\n",
       "      <td>none_none</td>\n",
       "      <td>none_none</td>\n",
       "      <td>none_none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>safebrowsing_clients_google_com</td>\n",
       "      <td>safebrowsing_cache_google_com</td>\n",
       "      <td>safebrowsing_clients_google_com</td>\n",
       "      <td>safebrowsing_cache_google_com</td>\n",
       "      <td>none_none</td>\n",
       "      <td>none_none</td>\n",
       "      <td>none_none</td>\n",
       "      <td>none_none</td>\n",
       "      <td>none_none</td>\n",
       "      <td>none_none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>www_apache_org</td>\n",
       "      <td>www_apache_org</td>\n",
       "      <td>download_eclipse_org</td>\n",
       "      <td>www_apache_org</td>\n",
       "      <td>www_apache_org</td>\n",
       "      <td>www_webtide_com</td>\n",
       "      <td>download_oracle_com</td>\n",
       "      <td>javadl_esd_secure_oracle_com</td>\n",
       "      <td>www_caucho_com</td>\n",
       "      <td>www_apache_org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>www_webtide_com</td>\n",
       "      <td>download_oracle_com</td>\n",
       "      <td>www_caucho_com</td>\n",
       "      <td>download_oracle_com</td>\n",
       "      <td>www_webtide_com</td>\n",
       "      <td>www_apache_org</td>\n",
       "      <td>public_dhe_ibm_com</td>\n",
       "      <td>www_webtide_com</td>\n",
       "      <td>www_apache_org</td>\n",
       "      <td>www_apache_org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>public_dhe_ibm_com</td>\n",
       "      <td>jope_ow2_org</td>\n",
       "      <td>download_oracle_com</td>\n",
       "      <td>public_dhe_ibm_com</td>\n",
       "      <td>jope_ow2_org</td>\n",
       "      <td>master_dl_sourceforge_net</td>\n",
       "      <td>www_apache_org</td>\n",
       "      <td>download_eclipse_org</td>\n",
       "      <td>www_apache_org</td>\n",
       "      <td>public_dhe_ibm_com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      site1                          site2  \\\n",
       "session_id                                                                   \n",
       "21669       safebrowsing_clients_google_com  safebrowsing_cache_google_com   \n",
       "54843       safebrowsing_clients_google_com  safebrowsing_cache_google_com   \n",
       "77292                        www_apache_org                 www_apache_org   \n",
       "114021                      www_webtide_com            download_oracle_com   \n",
       "146670                   public_dhe_ibm_com                   jope_ow2_org   \n",
       "\n",
       "                                      site3                          site4  \\\n",
       "session_id                                                                   \n",
       "21669                             none_none                      none_none   \n",
       "54843       safebrowsing_clients_google_com  safebrowsing_cache_google_com   \n",
       "77292                  download_eclipse_org                 www_apache_org   \n",
       "114021                       www_caucho_com            download_oracle_com   \n",
       "146670                  download_oracle_com             public_dhe_ibm_com   \n",
       "\n",
       "                      site5                      site6                site7  \\\n",
       "session_id                                                                    \n",
       "21669             none_none                  none_none            none_none   \n",
       "54843             none_none                  none_none            none_none   \n",
       "77292        www_apache_org            www_webtide_com  download_oracle_com   \n",
       "114021      www_webtide_com             www_apache_org   public_dhe_ibm_com   \n",
       "146670         jope_ow2_org  master_dl_sourceforge_net       www_apache_org   \n",
       "\n",
       "                                   site8           site9              site10  \n",
       "session_id                                                                    \n",
       "21669                          none_none       none_none           none_none  \n",
       "54843                          none_none       none_none           none_none  \n",
       "77292       javadl_esd_secure_oracle_com  www_caucho_com      www_apache_org  \n",
       "114021                   www_webtide_com  www_apache_org      www_apache_org  \n",
       "146670              download_eclipse_org  www_apache_org  public_dhe_ibm_com  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s_youtube_com                           142\n",
       "i1_ytimg_com                            141\n",
       "www_youtube_com                         130\n",
       "www_facebook_com                         98\n",
       "www_google_fr                            80\n",
       "apis_google_com                          56\n",
       "r4___sn_gxo5uxg_jqbe_googlevideo_com     54\n",
       "www_google_com                           51\n",
       "r1___sn_gxo5uxg_jqbe_googlevideo_com     47\n",
       "r2___sn_gxo5uxg_jqbe_googlevideo_com     43\n",
       "r3___sn_gxo5uxg_jqbe_googlevideo_com     40\n",
       "s_ytimg_com                              35\n",
       "s_static_ak_facebook_com                 32\n",
       "twitter_com                              31\n",
       "platform_twitter_com                     30\n",
       "static_ak_facebook_com                   30\n",
       "vk_com                                   28\n",
       "mts0_google_com                          27\n",
       "translate_google_fr                      25\n",
       "yt3_ggpht_com                            25\n",
       "www_melty_fr                             21\n",
       "clients1_google_com                      20\n",
       "deliv_leboncoin_fr                       19\n",
       "api_bing_com                             18\n",
       "clients1_google_fr                       17\n",
       "accounts_google_com                      16\n",
       "mts1_google_com                          16\n",
       "plus_googleapis_com                      16\n",
       "static_leboncoin_fr                      16\n",
       "www_dailymotion_com                      16\n",
       "                                       ... \n",
       "cdn24_ne_be                               1\n",
       "landing_r2games_com                       1\n",
       "auto_img_v4_skyrock_net                   1\n",
       "lh3_ggpht_com                             1\n",
       "www_sefaireaider_com                      1\n",
       "account_live_com                          1\n",
       "ea_numericable_fr                         1\n",
       "fr_123rf_com                              1\n",
       "admin_brightcove_com                      1\n",
       "a400_idata_over_blog_com                  1\n",
       "p2_storage_canalblog_com                  1\n",
       "vodlocker_com                             1\n",
       "banniere_reussissonsensemble_fr           1\n",
       "static_bbc_co_uk                          1\n",
       "js_live_net                               1\n",
       "www_vends_ta_culotte_com                  1\n",
       "static_bbci_co_uk                         1\n",
       "idata_over_blog_com                       1\n",
       "exashare_com                              1\n",
       "raymichemin_canalblog_com                 1\n",
       "static_cloud_media_fr                     1\n",
       "graphics8_nytimes_com                     1\n",
       "i_imgur_com                               1\n",
       "rubicon_match_dotomi_com                  1\n",
       "www_jobijoba_com                          1\n",
       "p_sfx_ms                                  1\n",
       "www_financialsmartbot_com                 1\n",
       "images_ted_com                            1\n",
       "api_eu_kgoma_com                          1\n",
       "s_radio_canada_ca                         1\n",
       "Name: site1, Length: 448, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sites[train_df[\"target\"] == 1][\"site1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_df[\"target\"]\n",
    "train_df.drop('target', axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sites_list = [\" \".join(row.tolist()) for _, row in train_sites.iterrows()]\n",
    "train_sites_list.append(\"unknown_unknown\")\n",
    "test_sites_list = [\" \".join(row.tolist()) for _, row in test_sites.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 10), (82797, 10))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sites.shape, test_sites.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253562, 41600), (82797, 9088))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(train_sites_list), len(set(train_sites[sites].values.flatten()))), \\\n",
    "(len(test_sites_list), len(set(test_sites[sites].values.flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "# train_sites_list = train_sites_list[:9] + [train_sites_list[-1]]\n",
    "# test_sites_list = test_sites_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X_train_cv = cv.fit_transform(train_sites_list)\n",
    "X_train_cv = X_train_cv[:-1, :]\n",
    "X_test_cv = cv.transform(test_sites_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 41601), (82797, 41601))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cv.shape, X_test_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(train_sites[sites].values.flatten()) - set(cv.vocabulary_) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "X_train_sparse = transformer.fit_transform(X_train_cv)\n",
    "X_test_sparse = transformer.transform(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 41601), (82797, 41601))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse.shape, X_test_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===== BASELINE ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_auc_lr_valid(X, y, C=1.0, ratio=0.9, seed=17):\n",
    "    '''\n",
    "    X, y – выборка\n",
    "    ratio – в каком отношении поделить выборку\n",
    "    C, seed – коэф-т регуляризации и random_state \n",
    "              логистической регрессии\n",
    "    '''\n",
    "    train_len = int(ratio * X.shape[0])\n",
    "    X_train = X[:train_len, :]\n",
    "    X_valid = X[train_len:, :]\n",
    "    y_train = y[:train_len]\n",
    "    y_valid = y[train_len:]\n",
    "    \n",
    "    logit = LogisticRegression(C=C, n_jobs=-1, random_state=seed)\n",
    "    \n",
    "    logit.fit(X_train, y_train)\n",
    "    \n",
    "    valid_pred = logit.predict_proba(X_valid)[:, 1]\n",
    "    \n",
    "    return round(roc_auc_score(y_valid, valid_pred), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.73 s, sys: 20 ms, total: 1.75 s\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit = LogisticRegression(n_jobs=-1, random_state=17)\n",
    "logit.fit(X_train_sparse, y_train)\n",
    "y_pred = logit.predict_proba(X_test_sparse)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1, param_grid={'C': [1, 2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "lr = LogisticRegression(n_jobs=-1)\n",
    "param_grid = {\"C\": [1,2,3]}\n",
    "grid = GridSearchCV(lr, param_grid=param_grid, cv=5, scoring=\"roc_auc\")\n",
    "grid.fit(X_train_sparse, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.87516, std: 0.04861, params: {'C': 1},\n",
       " mean: 0.88119, std: 0.04393, params: {'C': 2},\n",
       " mean: 0.88408, std: 0.04158, params: {'C': 3}]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 944 ms, sys: 4 ms, total: 948 ms\n",
      "Wall time: 955 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.91635999999999995"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_auc_lr_valid(X_train_sparse, y_train, C=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(y_pred, PATH_TO_DATA + \"/submit/simple_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===== MY ======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_train = pd.DataFrame(index=train_df.index)\n",
    "feat_test = pd.DataFrame(index=test_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**year_month_scaled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "feat_train['year_month'] = train_df['time1'].apply(lambda ts: 100 * ts.year + ts.month)\n",
    "feat_test['year_month'] = test_df['time1'].apply(lambda ts: 100 * ts.year + ts.month)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(feat_train['year_month'].values.reshape(-1, 1))\n",
    "\n",
    "feat_train['year_month_scaled'] = scaler.transform(feat_train['year_month'].values.reshape(-1, 1))\n",
    "feat_test['year_month_scaled'] = scaler.transform(feat_test['year_month'].values.reshape(-1, 1))\n",
    "\n",
    "X_train_sparse_new = csr_matrix(hstack([X_train_sparse, \n",
    "                                        feat_train['year_month_scaled'].values.reshape(-1, 1)]))\n",
    "X_test_sparse_new = csr_matrix(hstack([X_test_sparse, \n",
    "                                       feat_test['year_month_scaled'].values.reshape(-1, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.83 s, sys: 0 ns, total: 1.83 s\n",
      "Wall time: 1.85 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92730999999999997"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_auc_lr_valid(X_train_sparse_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.3 s, sys: 48 ms, total: 2.35 s\n",
      "Wall time: 2.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit = LogisticRegression(n_jobs=-1, random_state=17)\n",
    "logit.fit(X_train_sparse_new, y_train)\n",
    "y_pred = logit.predict_proba(X_test_sparse_new)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(y_pred, PATH_TO_DATA + \"/submit/simple_tfidf_yms.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**start_hour_scaled, weekday_scaled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_sparse_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_sparse_new' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feat_train['start_hour'] = train_df['time1'].apply(lambda ts: ts.hour)\n",
    "feat_test['start_hour'] = test_df['time1'].apply(lambda ts: ts.hour)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(feat_train['start_hour'].values.reshape(-1, 1))\n",
    "\n",
    "feat_train['start_hour_scaled'] = scaler.transform(feat_train['start_hour'].values.reshape(-1, 1))\n",
    "feat_test['start_hour_scaled'] = scaler.transform(feat_test['start_hour'].values.reshape(-1, 1))\n",
    "\n",
    "X_train_sparse_new = csr_matrix(hstack([X_train_sparse_new, \n",
    "                                        feat_train['start_hour_scaled'].values.reshape(-1, 1)]))\n",
    "X_test_sparse_new = csr_matrix(hstack([X_test_sparse_new, \n",
    "                                       feat_test['start_hour_scaled'].values.reshape(-1, 1)]))\n",
    "\n",
    "print(get_auc_lr_valid(X_train_sparse_new, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_sparse_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_sparse_new' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feat_train['weekday'] = train_df['time1'].apply(lambda ts: ts.dayofweek)\n",
    "feat_test['weekday'] = test_df['time1'].apply(lambda ts: ts.dayofweek)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(feat_train['weekday'].values.reshape(-1, 1))\n",
    "\n",
    "feat_train['weekday_scaled'] = scaler.transform(feat_train['weekday'].values.reshape(-1, 1))\n",
    "feat_test['weekday_scaled'] = scaler.transform(feat_test['weekday'].values.reshape(-1, 1))\n",
    "\n",
    "X_train_sparse_new = csr_matrix(hstack([X_train_sparse_new, \n",
    "                                        feat_train['weekday_scaled'].values.reshape(-1, 1)]))\n",
    "X_test_sparse_new = csr_matrix(hstack([X_test_sparse_new, \n",
    "                                       feat_test['weekday_scaled'].values.reshape(-1, 1)]))\n",
    "\n",
    "print(get_auc_lr_valid(X_train_sparse_new, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.15 s, sys: 16 ms, total: 2.17 s\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit = LogisticRegression(n_jobs=-1, random_state=17)\n",
    "logit.fit(X_train_sparse_new, y_train)\n",
    "y_pred = logit.predict_proba(X_test_sparse_new)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(y_pred, PATH_TO_DATA + \"/submit/tfidf_yms_shs_ws.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97677\n"
     ]
    }
   ],
   "source": [
    "feat_train['is_youtube'] = train_df['site1'].apply(lambda s: 1 if (\"youtube\" in s) or (\"ytimg\" in s) else 0)\n",
    "feat_test['is_youtube'] = test_df['site1'].apply(lambda s: 1 if (\"youtube\" in s) or (\"ytimg\" in s) else 0)\n",
    "\n",
    "X_train_sparse_new = csr_matrix(hstack([X_train_sparse_new,  \n",
    "                                        feat_train['is_youtube'].values.reshape(-1, 1)]))\n",
    "X_test_sparse_new = csr_matrix(hstack([X_test_sparse_new, \n",
    "                                       feat_test['is_youtube'].values.reshape(-1, 1)]))\n",
    "print(get_auc_lr_valid(X_train_sparse_new, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97681\n"
     ]
    }
   ],
   "source": [
    "feat_train['is_social'] = train_df['site1'].apply(lambda s: 1 if (\"facebook\" in s) or (\"vk_\" in s) else 0)\n",
    "feat_test['is_social'] = test_df['site1'].apply(lambda s: 1 if (\"facebook\" in s) or (\"vk_\" in s) else 0)\n",
    "\n",
    "X_train_sparse_new = csr_matrix(hstack([X_train_sparse_new,  \n",
    "                                        feat_train['is_social'].values.reshape(-1, 1)]))\n",
    "X_test_sparse_new = csr_matrix(hstack([X_test_sparse_new, \n",
    "                                       feat_test['is_social'].values.reshape(-1, 1)]))\n",
    "print(get_auc_lr_valid(X_train_sparse_new, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9768\n"
     ]
    }
   ],
   "source": [
    "feat_train['is_google'] = train_df['site1'].apply(lambda s: 1 if \"google\" in s else 0)\n",
    "feat_test['is_google'] = test_df['site1'].apply(lambda s: 1 if \"google\" in s else 0)\n",
    "\n",
    "X_train_sparse_new = csr_matrix(hstack([X_train_sparse_new,  \n",
    "                                        feat_train['is_google'].values.reshape(-1, 1)]))\n",
    "X_test_sparse_new = csr_matrix(hstack([X_test_sparse_new, \n",
    "                                       feat_test['is_google'].values.reshape(-1, 1)]))\n",
    "print(get_auc_lr_valid(X_train_sparse_new, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 964 ms, sys: 200 ms, total: 1.16 s\n",
      "Wall time: 24.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logit = LogisticRegressionCV(n_jobs=-1, random_state=17)\n",
    "logit.fit(X_train_sparse_new, y_train)\n",
    "y_pred = logit.predict_proba(X_test_sparse_new)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(y_pred, PATH_TO_DATA + \"/submit/tfidf_yms_shs_ws_first_sites.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
